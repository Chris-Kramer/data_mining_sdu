{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{ {N, N N}, {N, N, D}, {N, D, D}, {D, D, D}, {D, D, N}, {D, N, N} }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](imgs/Screenshot_3.png)  \n",
    "\n",
    "{0, 1, 2, 3, 4, 5, 6 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](imgs/Screenshot_4.png)  \n",
    "\n",
    "{0, 1, 2, 3, 4, 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](imgs/Screenshot_5.png)  \n",
    "\n",
    "{3, 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](imgs/Screenshot_6.png)  \n",
    "\n",
    "{1, 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](imgs/Screenshot_7.png)  \n",
    "\n",
    "{5, 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](imgs/Screenshot_8.png)\n",
    "\n",
    "{6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_10.png)  \n",
    "\n",
    "For each individual component  \n",
    "D = {(S, S, F), (S, F, S), (F, S, S)}\n",
    "\n",
    "For the whole system  \n",
    "{S, S, F}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_11.png)  \n",
    "\n",
    "For the individual components  \n",
    "E = {(S, S, F), (S, F, S), (F, S, S), (S, S, S)}  \n",
    "\n",
    "For the whole system\n",
    "{S, S, F, S}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_12.png)  \n",
    "\n",
    "For the individual components  \n",
    "\n",
    "G = {(S, S, F), (S, F, S), (S, S, S)}  \n",
    "\n",
    "For the whole system:  \n",
    "{S, S, S}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_13.png)  \n",
    "\n",
    "To Get the complementary of G, we must list all possible outcomes and remove those that are part of G  \n",
    "\n",
    "Sample space = {(S, S, S), (S, S, F), (S, F, S), (S, F, F)\n",
    "                (F, F, F), (F, F, S), (F, S, F), (F, S, S)}  \n",
    "\n",
    "\n",
    "We then remove G which gives  \n",
    "{(S, F, F) (F, F, F), (F, F, S), (F, S, F), (F, S, S)}  \n",
    "\n",
    "With the intersection of D an G we get:  \n",
    "{(S, S, F), (S, F, S)}  \n",
    "\n",
    "The union of D and G gives:  \n",
    "{(S, S, F), (S, F, S), (S, S, S)}  \n",
    "\n",
    "The union of E and G gives:  \n",
    "{(S, S, F), (S, F, S), (F, S, S), (S, S, S)}  \n",
    "\n",
    "The intersection og E and G gives  \n",
    "{(S, S, F), (S, F, S), (S, S, S)} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_14.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this we use the conditional probability formula:  \n",
    "\n",
    "![title](imgs/Screenshot_16.png)  \n",
    "\n",
    "which converted to our case is  \n",
    "\n",
    "Pr(B | A) = Pr(A and B) / Pr(A)  \n",
    "\n",
    "which gives  \n",
    "\n",
    "Pr(B | A) = 0.3 / 0.6  \n",
    "\n",
    "so 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_A = 6/10\n",
    "pr_B = 4/10\n",
    "pr_A_and_B = 3/10\n",
    "pr_A_and_B / pr_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So procedure but we have to change the prior  \n",
    "\n",
    "![title](imgs/Screenshot_16.png)  \n",
    "\n",
    "which converted to our case is  \n",
    "\n",
    "Pr(A | B) = Pr(A and B) / Pr(B)  \n",
    "\n",
    "which gives  \n",
    "\n",
    "Pr(A | B) = 0.3 / 0.4  \n",
    "\n",
    "so 75%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499999999999999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_A = 6/10\n",
    "pr_B = 4/10\n",
    "pr_A_and_B = 3/10\n",
    "pr_A_and_B / pr_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use bayes theorem:  \n",
    "![title](imgs/Screenshot_19.png)   \n",
    "\n",
    "\n",
    "So we have the following:  \n",
    "\n",
    "Pr( sick ) = 1/1000  \n",
    "Pr( Positve | sick ) = 99/100  \n",
    "Pr( Positve | healthy) = 2/100   \n",
    "Pr( healthy ) = 999 / 1000 (This is the same as 1 - Pr( sick ))\n",
    "\n",
    "Which gives the following formula:  \n",
    "\n",
    "Pr( Sick | Positve) = ( Pr( Positive | Sick ) * Pr( sick ) ) / (Pr( Positive ) )   \n",
    "\n",
    "To get the probability of B or Pr( Postive ) we need to do the following:  \n",
    "![title](imgs/Screenshot_20.png)  \n",
    "\n",
    "Pr( Positve ) = ( ( Pr( Positive | sick ) * Pr (sick) )+ Pr(sick | healthy) * Pr( Healthy ) )\n",
    "\n",
    "So the full formula is:  \n",
    "\n",
    "![title](imgs/Screenshot_21.png)  \n",
    "\n",
    "Pr( Sick | Positve) = ( Pr( Positive | Sick ) * Pr( sick ) ) / Pr( Postive ))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047210300429184546"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)\n",
    "\n",
    "prob_sick = 1/1000 # P(A)\n",
    "prob_healthy = 999/1000 #P(not A)\n",
    "prob_positive_sick = 99/100 # P(B | A)\n",
    "prob_positive_healthy = 2/100 # P(B | not A)\n",
    "\n",
    "prob_positve = prob_positive_sick * prob_sick + prob_positive_healthy * prob_healthy # P( B )\n",
    "prob_positive_sick * prob_sick / prob_positve #P(A | B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For at løse denne skal vi tage sandsynlighederne fra hver classifer og gange dem med sandsynligheden af hypotesen som classifieren angiver.\n",
    "\n",
    "Pr(h1 | D) = 0.2\n",
    "Pr(h2 | D) = 0.1\n",
    "Pr(h3 | D) = 0.7\n",
    "\n",
    "Så med **o1** skal vi gøre følgende:\n",
    "\n",
    "Pr(+ | h1 ) = 0.4\n",
    "Pr(+ | h2 ) = 0.4\n",
    "Pr(+ | h3) = 0.6\n",
    "\n",
    "Vi siger Pr(+ | h1) * Pr(h1 | D) + Pr(+ | h2 ) * Pr(h2 | D) + Pr(+ | h3) * Pr(h3 | D)  \n",
    "\n",
    "Hvilket er (0.4 * 0.2) + (0.4 * 0.1) + (0.6 * 0.7) = **0.54**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O1 Pr( + | Bayes Optimal): 0.54\n",
      "O1 Pr( - | Bayes Optimal): 0.46\n",
      "O2 Pr( + | Bayes Optimal): 0.55\n",
      "O2 Pr( - | Bayes Optimal): 0.45\n",
      "O3 Pr( + | Bayes Optimal): 0.55\n",
      "O3 Pr( + | Bayes Optimal): 0.45\n"
     ]
    }
   ],
   "source": [
    "#O1\n",
    "print(f\"O1 Pr( + | Bayes Optimal): {round((0.4 * 0.2) + (0.4 * 0.1) + (0.6 * 0.7), 2)}\")\n",
    "print(f\"O1 Pr( - | Bayes Optimal): {round((0.6 * 0.2) + (0.6 * 0.1) + (0.4 * 0.7), 2)}\")\n",
    "print(f\"O2 Pr( + | Bayes Optimal): {round((0.8 * 0.2) + (0.4 * 0.1) + (0.5 * 0.7), 2)}\")\n",
    "print(f\"O2 Pr( - | Bayes Optimal): {round((0.2 * 0.2) + (0.6 * 0.1) + (0.5 * 0.7), 2)}\")\n",
    "print(f\"O3 Pr( + | Bayes Optimal): {round((0.6 * 0.2) + (0.8 * 0.1) + (0.5 * 0.7), 2)}\")\n",
    "print(f\"O3 Pr( + | Bayes Optimal): {round((0.4 * 0.2) + (0.2 * 0.1) + (0.5 * 0.7), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olsen\n",
      "forbid\n",
      "allow\n",
      "\n",
      "Frandsen\n",
      "forbid\n",
      "allow\n",
      "\n",
      "Jensen\n",
      "forbid\n",
      "allow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_unique_values(my_list):    \n",
    "    unique_list = []\n",
    "    for element in my_list:\n",
    "        if element not in unique_list:\n",
    "            unique_list.append(element)\n",
    "    return unique_list\n",
    "\n",
    "def flatten(my_list):\n",
    "    flat_list = []\n",
    "    for sub_list in my_list:\n",
    "        for element in sub_list:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "training = {\n",
    "    \"olsen\": [\"forbid\", \"forbid\", \"forbid\", \"allow\", \"allow\", \"allow\", \"allow\", \"forbid\", \"forbid\", \"allow\"], # Olsen\n",
    "    \"frandsen\":[\"forbid\", \"forbid\", \"forbid\", \"forbid\", \"forbid\", \"allow\", \"allow\", \"allow\", \"allow\", \"forbid\"], # Frandsen\n",
    "    \"jensen\": [\"allow\", \"forbid\", \"allow\", \"forbid\", \"allow\", \"forbid\", \"allow\", \"forbid\", \"allow\", \"forbid\"], # Jensen\n",
    "    \"allow\": [\"yes\", # 1\n",
    "    \"yes\", # 2\n",
    "    \"yes\", # 3\n",
    "    \"yes\", # 4\n",
    "    \"yes\", # 5\n",
    "    \"yes\", # 6\n",
    "    \"yes\", # 7\n",
    "    \"no\", # 8\n",
    "    \"no\", # 9\n",
    "    \"no\" # 10\n",
    " ]\n",
    "\n",
    "}\n",
    "\n",
    "feature_names =  [\"Olsen\", \"Frandsen\", \"Jensen\"]\n",
    "y_labels = [\n",
    "    \"yes\", # 1\n",
    "    \"yes\", # 2\n",
    "    \"yes\", # 3\n",
    "    \"yes\", # 4\n",
    "    \"yes\", # 5\n",
    "    \"yes\", # 6\n",
    "    \"yes\", # 7\n",
    "    \"no\", # 8\n",
    "    \"no\", # 9\n",
    "    \"no\" # 10\n",
    " ]\n",
    "\n",
    "train_values = get_unique_values(flatten(training))\n",
    "\n",
    "label_names = get_unique_values(y_labels)\n",
    "label_counts = [y_labels.count(label_name) for label_name in label_names]\n",
    "\n",
    "#counts = [0 for _ in range(len(labels))]\n",
    "for z, train in enumerate(training):\n",
    "    print(f\"{feature_names[z]}\")\n",
    "    value_counts = [0 for _ in range(len(train_values))]\n",
    "    \n",
    "    \n",
    "    \n",
    "    labs = {\"yes\": 0, \"no\": 0}\n",
    "    for j, value in enumerate(train):\n",
    "\n",
    "        for i, train_value_label in enumerate(train_values):\n",
    "            if value == train_value_label:\n",
    "                value_counts[i] += 1\n",
    "    \n",
    "    res = []\n",
    "    for s, value_count in enumerate(value_counts):\n",
    "        print(train_values[s])\n",
    "        for l, label_count in enumerate(label_counts):\n",
    "            #print(f\"{train_values[s]}: {value_count} / {label_names[l]}: {label_count}\")\n",
    "            res.append(value_count / label_count)\n",
    "    \n",
    "   \n",
    "    #for label_name in label_names: \n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41257050765511666\n",
      "0.5874294923448833\n",
      "[0, 1, 1]\n",
      "['yes']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "def get_unique_values(my_list):    \n",
    "    unique_list = []\n",
    "    for element in my_list:\n",
    "        if element not in unique_list:\n",
    "            unique_list.append(element)\n",
    "    return unique_list\n",
    "\n",
    "def flatten(my_list):\n",
    "    flat_list = []\n",
    "    for sub_list in my_list:\n",
    "        for element in sub_list:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "def convert_flat_list_to_numeric(flat_list):\n",
    "    categories = get_unique_values(flat_list)\n",
    "    return_sublist = []\n",
    "    for element in flat_list:\n",
    "        for i, category in enumerate(categories):\n",
    "            if element == category:\n",
    "                return_sublist.append(i)\n",
    "    return return_sublist    \n",
    "\n",
    "def convert_to_numeric(data):\n",
    "    return_data = []\n",
    "    for sublist in data:\n",
    "        return_data.append(convert_flat_list_to_numeric(sublist))\n",
    "    return return_data\n",
    "\n",
    "training = [\n",
    "    [\"forbid\", \"forbid\", \"allow\"], # 1\n",
    "    [\"forbid\", \"forbid\", \"forbid\"], # 2\n",
    "    [\"forbid\", \"forbid\", \"allow\"], # 3\n",
    "    [\"allow\", \"forbid\", \"forbid\"], # 4\n",
    "    [\"allow\", \"forbid\", \"allow\"], # 5\n",
    "    [\"allow\", \"allow\", \"allow\"], # 6\n",
    "    [\"allow\", \"allow\", \"forbid\"], # 7\n",
    "    [\"forbid\", \"allow\", \"forbid\"], # 8\n",
    "    [\"forbid\", \"allow\", \"allow\"], # 9\n",
    "    [\"allow\", \"forbid\", \"forbid\"], # 10\n",
    " ]\n",
    "\n",
    "training = np.array(convert_to_numeric(training), dtype = \"object\")\n",
    "y_labels = np.array([\n",
    "    \"yes\", # 1\n",
    "    \"yes\", # 2\n",
    "    \"yes\", # 3\n",
    "    \"yes\", # 4\n",
    "    \"yes\", # 5\n",
    "    \"yes\", # 6\n",
    "    \"no\", # 7\n",
    "    \"no\", # 8\n",
    "    \"no\", # 9\n",
    "    \"no\" # 10\n",
    " ])\n",
    "\n",
    "#y_labels, label_names = np.array(convert_to_numeric(y_labels))\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(training, y_labels)\n",
    "\n",
    "res = model.predict_proba(np.array([[1, 1, 0]], dtype= \"object\"))\n",
    "\n",
    "for val in res:\n",
    "    for v in val:\n",
    "        print(v )\n",
    "\n",
    "print(convert_flat_list_to_numeric([\"allow\", \"forbid\", \"forbid\"])) \n",
    "# allow = 0\n",
    "# forbid = 1      \n",
    "print(model.predict(np.array([[0, 0, 1]], dtype= \"object\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \t\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "\n",
    "\t\"\"\"\tscore = (y_true - y_pred) / len(y_true) \"\"\"\n",
    "\n",
    "\treturn round(float(sum(y_pred == y_true))/float(len(y_true)) * 100 ,2)\n",
    "\n",
    "def pre_processing(df):\n",
    "\n",
    "\t\"\"\" partioning data into features and target \"\"\"\n",
    "\n",
    "\tX = df.drop([df.columns[-1]], axis = 1)\n",
    "\ty = df[df.columns[-1]]\n",
    "\n",
    "\treturn X, y\n",
    "\n",
    "\n",
    "\n",
    "class  NaiveBayes:\n",
    "\n",
    "\t\"\"\"\n",
    "\t\tBayes Theorem:\n",
    "\t\t\t\t\t\t\t\t\t\tLikelihood * Class prior probability\n",
    "\t\t\t\tPosterior Probability = -------------------------------------\n",
    "\t\t\t\t\t\t\t\t\t\t\tPredictor prior probability\n",
    "\t\t\t\t\n",
    "\t\t\t\t\t\t\t  \t\t\t P(x|c) * p(c)\n",
    "\t\t\t\t\t\t\t   P(c|x) = ------------------ \n",
    "\t\t\t\t\t\t\t\t\t\t\t  P(x)\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t\tAttributes:\n",
    "\t\t\t\tlikelihoods: Likelihood of each feature per class\n",
    "\t\t\t\tclass_priors: Prior probabilities of classes \n",
    "\t\t\t\tpred_priors: Prior probabilities of features \n",
    "\t\t\t\tfeatures: All features of dataset\n",
    "\t\t\"\"\"\n",
    "\t\tself.features = list\n",
    "\t\tself.likelihoods = {}\n",
    "\t\tself.class_priors = {}\n",
    "\t\tself.pred_priors = {}\n",
    "\n",
    "\t\tself.X_train = np.array\n",
    "\t\tself.y_train = np.array\n",
    "\t\tself.train_size = int\n",
    "\t\tself.num_feats = int\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\n",
    "\t\tself.features = list(X.columns)\n",
    "\t\tself.X_train = X\n",
    "\t\tself.y_train = y\n",
    "\t\tself.train_size = X.shape[0]\n",
    "\t\tself.num_feats = X.shape[1]\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tself.likelihoods[feature] = {}\n",
    "\t\t\tself.pred_priors[feature] = {}\n",
    "\n",
    "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
    "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
    "\n",
    "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
    "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
    "\n",
    "\t\tself._calc_class_prior()\n",
    "\t\tself._calc_likelihoods()\n",
    "\t\tself._calc_predictor_prior()\n",
    "\n",
    "\tdef _calc_class_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(c) - Prior Class Probability \"\"\"\n",
    "\n",
    "\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n",
    "\n",
    "\tdef _calc_likelihoods(self):\n",
    "\n",
    "\t\t\"\"\" P(x|c) - Likelihood \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
    "\n",
    "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
    "\t\t\t\t\tself.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count\n",
    "\n",
    "\n",
    "\tdef _calc_predictor_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(x) - Evidence \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\n",
    "\t\t\tfor feat_val, count in feat_vals.items():\n",
    "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n",
    "\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\n",
    "\t\t\"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
    "\n",
    "\t\tresults = []\n",
    "\t\tX = np.array(X)\n",
    "\n",
    "\t\tfor query in X:\n",
    "\t\t\tprobs_outcome = {}\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\tprior = self.class_priors[outcome]\n",
    "\t\t\t\tlikelihood = 1\n",
    "\t\t\t\tevidence = 1\n",
    "\n",
    "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
    "\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
    "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
    "\n",
    "\t\t\t\tposterior = (likelihood * prior) / (evidence)\n",
    "\n",
    "\t\t\t\tprobs_outcome[outcome] = posterior\n",
    "\n",
    "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
    "\t\t\tresults.append(result)\n",
    "\n",
    "\t\treturn np.array(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Olsen  fransen  jsensen allow\n",
      "0      0        0        1   yes\n",
      "1      0        0        1   yes\n",
      "2      0        0        1   yes\n",
      "3      1        0        0   yes\n",
      "4      1        0        1   yes\n",
      "5      1        1        0   yes\n",
      "6      1        1        1   yes\n",
      "7      0        1        0    no\n",
      "8      0        1        1    no\n",
      "9      1        1        0    no\n",
      "0    yes\n",
      "1    yes\n",
      "2    yes\n",
      "3    yes\n",
      "4    yes\n",
      "5    yes\n",
      "6    yes\n",
      "7     no\n",
      "8     no\n",
      "9     no\n",
      "Name: allow, dtype: object\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('int64'), dtype('<U1')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [83], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(y)\n\u001b[0;32m     11\u001b[0m nb_clf \u001b[39m=\u001b[39m NaiveBayes()\n\u001b[1;32m---> 12\u001b[0m nb_clf\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "Cell \u001b[1;32mIn [79], line 72\u001b[0m, in \u001b[0;36mNaiveBayes.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     69\u001b[0m \t\t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_priors[feature]\u001b[39m.\u001b[39mupdate({feat_val: \u001b[39m0\u001b[39m})\n\u001b[0;32m     71\u001b[0m \t\t\u001b[39mfor\u001b[39;00m outcome \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39munique(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train):\n\u001b[1;32m---> 72\u001b[0m \t\t\t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlikelihoods[feature]\u001b[39m.\u001b[39mupdate({feat_val\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39moutcome:\u001b[39m0\u001b[39m})\n\u001b[0;32m     73\u001b[0m \t\t\t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_priors\u001b[39m.\u001b[39mupdate({outcome: \u001b[39m0\u001b[39m})\n\u001b[0;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc_class_prior()\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('int64'), dtype('<U1')) -> None"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "olsen = training[0]\n",
    "fransen = training[2]\n",
    "jensen = training[1]\n",
    "          \n",
    "df = pd.DataFrame(training, columns = [\"Olsen\", \"fransen\", \"jsensen\"])\n",
    "df[\"allow\"] = y_labels\n",
    "print(df)\n",
    "X, y = pre_processing(df)\n",
    "print(y)\n",
    "nb_clf = NaiveBayes()\n",
    "nb_clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allow   no  yes  All\n",
      "olsen               \n",
      "allow    3    2    5\n",
      "forbid   2    3    5\n",
      "All      5    5   10\n",
      "allow\n",
      "no     0.6\n",
      "yes    0.4\n",
      "All    0.5\n",
      "dtype: float64\n",
      "allow\n",
      "no     0.4\n",
      "yes    0.6\n",
      "All    0.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"olsen\": [\"forbid\", \"forbid\", \"forbid\", \"allow\", \"allow\", \"allow\", \"allow\", \"forbid\", \"forbid\", \"allow\"], # Olsen\n",
    "    \"frandsen\":[\"forbid\", \"forbid\", \"forbid\", \"forbid\", \"forbid\", \"allow\", \"allow\", \"allow\", \"allow\", \"forbid\"], # Frandsen\n",
    "    \"jensen\": [\"allow\", \"forbid\", \"allow\", \"forbid\", \"allow\", \"forbid\", \"allow\", \"forbid\", \"allow\", \"forbid\"], # Jensen\n",
    "    \"allow\": [\"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\" ]\n",
    "\n",
    "})\n",
    "\n",
    "#for col in df:\n",
    "#    print(df.groupby(col).size())\n",
    "    #print(col)\n",
    "\n",
    "#res = df.groupby(['olsen', 'allow']).size()\n",
    "res = pd.crosstab(index = df[\"frandsen\"], columns=df[\"allow\"], margins = True)\n",
    "print(res)\n",
    "res.iloc[2, 0]\n",
    "res.iloc[2, 1]\n",
    "\n",
    "\n",
    "print(res.iloc[0] / res.iloc[2])\n",
    "print(res.iloc[1] / res.iloc[2])\n",
    "\n",
    "#print(res.iloc[0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa82987a71ca0339a52998cd22613b0c002bda8349fa32a0cb67ceec3936a2bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
