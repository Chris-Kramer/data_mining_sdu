{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning with Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cluster the probability estimates is given by:  \n",
    "\n",
    "![title](imgs/Screenshot_24.png)  \n",
    "\n",
    "Here d is refering to the number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi, sqrt, e\n",
    "import numpy as np\n",
    "\n",
    "def get_cluster_prob(sigma: np.ndarray, mean_vector: np.ndarray, x: np.ndarray):\n",
    "    \"\"\" \n",
    "    Takes a point x, a sigma, a mean vector\n",
    "    returns the probability density function\n",
    "    \"\"\"\n",
    "\n",
    "    sigma_inverse = np.linalg.inv(sigma)\n",
    "    d = len(x)\n",
    "    x_minus_mean = x - mean_vector \n",
    "    distance = x_minus_mean @ sigma_inverse @ np.transpose(x_minus_mean)\n",
    "\n",
    "    dividing_part = 1 / sqrt( (2*pi)**d * np.linalg.det(sigma))\n",
    "    return dividing_part * e**(-(1/2) * distance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04307456098861524"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_A = np.array([\n",
    "    [3, 0],\n",
    "    [0, 3]\n",
    "])\n",
    "x = np.array([2.5, 3])\n",
    "mean_a = np.array([2, 2])\n",
    "\n",
    "pdf_a = get_cluster_prob(sigma_A, mean_a, x)\n",
    "pdf_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010086610510705838"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_B = np.array([\n",
    "    [2, 1],\n",
    "    [1, 4]\n",
    "])\n",
    "mean_B = np.array([5, 3])\n",
    "\n",
    "pdf_b = get_cluster_prob(sigma_B, mean_B, x)\n",
    "pdf_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016364660641528687"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_C = np.array([\n",
    "    [16, 0],\n",
    "    [0, 4]\n",
    "])\n",
    "mean_C = np.array([1, 4])\n",
    "\n",
    "pdf_C = get_cluster_prob(sigma_C, mean_C, x)\n",
    "pdf_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities are given by:  \n",
    "The first formula is the PDF we just calculated\n",
    "\n",
    "![title](imgs/Screenshot_3.png)\n",
    "![title](imgs/Screenshot_2.png)  \n",
    "![title](imgs/Screenshot_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of A: 0.5588771177638471\n",
      "\n",
      "probability of A: 0.08724679069423721\n",
      "\n",
      "probability of A: 0.3538760915419156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_A =  ( (pdf_a * 0.3 ) / ( (0.3 * pdf_a) + (0.2 * pdf_b) + (0.5 * pdf_C) ) )\n",
    "print(f\"probability of A: {prob_A}\")  \n",
    "print()\n",
    "\n",
    "prob_B =  ( (pdf_b * 0.2 ) / ( (0.3 * pdf_a) + (0.2 * pdf_b) + (0.5 * pdf_C) ) )\n",
    "print(f\"probability of A: {prob_B}\")  \n",
    "print()\n",
    "\n",
    "prob_C =  ( (pdf_C * 0.5 ) / ( (0.3 * pdf_a) + (0.2 * pdf_b) + (0.5 * pdf_C) ) )\n",
    "print(f\"probability of A: {prob_C}\")  \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the neares neighbour density estimation:  \n",
    "![title](imgs/Screenshot_6.png)  \n",
    "\n",
    "Here V is the volume function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_dist(point_1: list[int | float], point_2: list[int | float]) -> float:\n",
    "    \"\"\" \n",
    "    Returns the euclidian distance between two points\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for p_1, p_2 in zip(point_1, point_2):\n",
    "        res.append((abs(p_1 - p_2))**2)\n",
    "        \n",
    "    return sum(res)**(1/2)\n",
    "\n",
    "\n",
    "def manhattan_dist(point_1: list[int | float], point_2: list[int | float]) -> float:\n",
    "    \"\"\" \n",
    "    Returns the manhattan distance between two points\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for p_1, p_2 in zip(point_1, point_2):\n",
    "        res.append(abs(p_1 - p_2))\n",
    "        \n",
    "    return sum(res)\n",
    "\n",
    "def get_k_smallest_indeces(input_list, k):\n",
    "        return sorted(range(len(input_list)), key=lambda sub: input_list[sub])[:k]\n",
    "\n",
    "\n",
    "def get_most_frequent_value(input_list):\n",
    "    return max(input_list, key = input_list.count)\n",
    "\n",
    "\n",
    "def get_k_neighbour(query: list[ int | float],\n",
    "                  points: list[int | float],\n",
    "                  k: int):\n",
    "    \"\"\"\n",
    "    Returns the k nearest neighbour to a point (a single neighbour)\n",
    "    \"\"\"\n",
    "\n",
    "    distances = []\n",
    "    for p in points:\n",
    "        distances.append(manhattan_dist(query, p))\n",
    "    knn = get_k_smallest_indeces(distances, k)\n",
    "    return points[knn[-1]]\n",
    "\n",
    "def manhattan_volume(r):\n",
    "    return 2 * r**2\n",
    "\n",
    "def manhantten_knn_density_func(k, n, point, nearest_neighbor):\n",
    "    dist = manhattan_dist(point, nearest_neighbor)\n",
    "    return k / ( n * manhattan_volume(dist) )\n",
    "\n",
    "def knn_kernel_density(k, points):\n",
    "    n = len(points)\n",
    "    for point in points:\n",
    "        nearest_neighbour = get_k_neighbour(point, points, k)\n",
    "        kernel_density = manhantten_knn_density_func(k, n, point, nearest_neighbour)\n",
    "        print(f\"Density at point {point} : {kernel_density}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density at point [1, 1] : 0.02631578947368421\n",
      "Density at point [1, 2] : 0.02631578947368421\n",
      "Density at point [2, 1] : 0.02631578947368421\n",
      "Density at point [2, 2] : 0.02631578947368421\n",
      "Density at point [3, 5] : 0.004210526315789474\n",
      "Density at point [3, 9] : 0.011695906432748537\n",
      "Density at point [3, 10] : 0.02631578947368421\n",
      "Density at point [4, 10] : 0.02631578947368421\n",
      "Density at point [4, 11] : 0.011695906432748537\n",
      "Density at point [7, 10] : 0.006578947368421052\n",
      "Density at point [9, 4] : 0.02631578947368421\n",
      "Density at point [9, 5] : 0.02631578947368421\n",
      "Density at point [10, 3] : 0.02631578947368421\n",
      "Density at point [10, 4] : 0.10526315789473684\n",
      "Density at point [10, 5] : 0.10526315789473684\n",
      "Density at point [10, 6] : 0.02631578947368421\n",
      "Density at point [10, 10] : 0.004210526315789474\n",
      "Density at point [11, 4] : 0.02631578947368421\n",
      "Density at point [11, 5] : 0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "points = [\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 1],\n",
    "    [2, 2],\n",
    "    [3, 5],\n",
    "    [3, 9],\n",
    "    [3, 10],\n",
    "    [4, 10],\n",
    "    [4, 11],\n",
    "    [7, 10],\n",
    "    [9, 4],\n",
    "    [9, 5],\n",
    "    [10, 3],\n",
    "    [10, 4],\n",
    "    [10, 5],\n",
    "    [10, 6],\n",
    "    [10, 10],\n",
    "    [11, 4],\n",
    "    [11, 5]\n",
    "]\n",
    "\n",
    "knn_kernel_density(k = 4, points = points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Screenshot_8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_vals(my_list):\n",
    "    unique_list = []\n",
    "    for val in my_list:\n",
    "        if val not in unique_list:\n",
    "            unique_list.append(val)\n",
    "    return unique_list\n",
    "\n",
    "def manhattan_dist(point_1: list[int | float], point_2: list[int | float]) -> float:\n",
    "    \"\"\" \n",
    "    Returns the manhattan distance between two points\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for p_1, p_2 in zip(point_1, point_2):\n",
    "        res.append(abs(p_1 - p_2))\n",
    "        \n",
    "    return sum(res)\n",
    "\n",
    "def get_k_smallest_indeces(input_list, k):\n",
    "        return sorted(range(len(input_list)), key=lambda sub: input_list[sub])[:k]\n",
    "\n",
    "\n",
    "def get_most_frequent_value(input_list):\n",
    "    return max(input_list, key = input_list.count)\n",
    "\n",
    "\n",
    "def get_k_neighbours(query: list[ int | float],\n",
    "                  points: list[int | float],\n",
    "                  k: int):\n",
    "    \"\"\"\n",
    "    Returns the k nearest neighbour to a point (a single neighbour)\n",
    "    \"\"\"\n",
    "\n",
    "    distances = []\n",
    "    for p in points:\n",
    "        distances.append(manhattan_dist(query, p))\n",
    "    nearest_neighbours = get_k_smallest_indeces(distances, k)\n",
    "    return [points[neighbour] for neighbour in nearest_neighbours]\n",
    "\n",
    "def SNN(points, queries, k):\n",
    "    \n",
    "    \n",
    "    total_neighbours = []\n",
    "    for q in queries:\n",
    "        neighbours = get_k_neighbours(q, points, k)\n",
    "        \n",
    "        for neighbour in neighbours:\n",
    "            total_neighbours.append(neighbour)\n",
    "    total_neighbours = get_unique_vals(total_neighbours)\n",
    "    return len(total_neighbours)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\n",
    "    [10, 6],\n",
    "    [9, 5],\n",
    "    [10, 5],\n",
    "    [11, 5],\n",
    "    [9, 4],\n",
    "    [10, 4],\n",
    "    [11, 4]\n",
    "]\n",
    "\n",
    "points = [\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 1],\n",
    "    [2, 2],\n",
    "    [3, 5],\n",
    "    [3, 9],\n",
    "    [3, 10],\n",
    "    [4, 10],\n",
    "    [4, 11],\n",
    "    [7, 10],\n",
    "    [9, 4],\n",
    "    [9, 5],\n",
    "    [10, 3],\n",
    "    [10, 4],\n",
    "    [10, 5],\n",
    "    [10, 6],\n",
    "    [10, 10],\n",
    "    [11, 4],\n",
    "    [11, 5]\n",
    "]\n",
    "\n",
    "\n",
    "SNN(points, queries, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def dbscan(D, eps, MinPts, verbose = True, snn = False, k = 5):\n",
    "    '''\n",
    "    Cluster the dataset `D` using the DBSCAN algorithm.\n",
    "    \n",
    "    dbscan takes a dataset `D` (a list of vectors), a threshold distance\n",
    "    `eps`, and a required number of points `MinPts`.\n",
    "    \n",
    "    It will return a list of cluster labels. The label -1 means noise, and then\n",
    "    the clusters are numbered starting from 1.\n",
    "    '''\n",
    " \n",
    "    # This list will hold the final cluster assignment for each point in D.\n",
    "    # There are two reserved values:\n",
    "    #    -1 - Indicates a noise point\n",
    "    #     0 - Means the point hasn't been considered yet.\n",
    "    # Initially all labels are 0.    \n",
    "    labels = [0]*len(D)\n",
    "\n",
    "    # C is the ID of the current cluster.    \n",
    "    C = 0\n",
    "    \n",
    "    # This outer loop is just responsible for picking new seed points--a point\n",
    "    # from which to grow a new cluster.\n",
    "    # Once a valid seed point is found, a new cluster is created, and the \n",
    "    # cluster growth is all handled by the 'expandCluster' routine.\n",
    "    \n",
    "    # For each point P in the Dataset D...\n",
    "    # ('P' is the index of the datapoint, rather than the datapoint itself.)\n",
    "    for P in range(0, len(D)):\n",
    "    \n",
    "        # Only points that have not already been claimed can be picked as new \n",
    "        # seed points.    \n",
    "        # If the point's label is not 0, continue to the next point.\n",
    "        if not (labels[P] == 0):\n",
    "           continue\n",
    "        \n",
    "        # Find all of P's neighboring points.\n",
    "        NeighborPts = region_query(D, P, eps, verbose, snn, k)\n",
    "        \n",
    "        # If the number is below MinPts, this point is noise. \n",
    "        # This is the only condition under which a point is labeled \n",
    "        # NOISE--when it's not a valid seed point. A NOISE point may later \n",
    "        # be picked up by another cluster as a boundary point (this is the only\n",
    "        # condition under which a cluster label can change--from NOISE to \n",
    "        # something else).\n",
    "        if len(NeighborPts) < MinPts:\n",
    "            labels[P] = -1\n",
    "        # Otherwise, if there are at least MinPts nearby, use this point as the \n",
    "        # seed for a new cluster.    \n",
    "        else: \n",
    "           C += 1\n",
    "           grow_cluster(D, labels, P, NeighborPts, C, eps, MinPts, verbose, snn, k)\n",
    "    \n",
    "    # All data has been clustered!\n",
    "    \n",
    "    for d, l in zip(D, labels):\n",
    "        print(f\"Point {d}, Cluster: {l}\")\n",
    "        \n",
    "    return labels\n",
    "\n",
    "\n",
    "def grow_cluster(D, labels, P, NeighborPts, C, eps, MinPts, verbose = True, snn = False, k = 5):\n",
    "    '''\n",
    "    Grow a new cluster with label `C` from the seed point `P`.\n",
    "    \n",
    "    This function searches through the dataset to find all points that belong\n",
    "    to this new cluster. When this function returns, cluster `C` is complete.\n",
    "    \n",
    "    Parameters:\n",
    "      `D`      - The dataset (a list of vectors)\n",
    "      `labels` - List storing the cluster labels for all dataset points\n",
    "      `P`      - Index of the seed point for this new cluster\n",
    "      `NeighborPts` - All of the neighbors of `P`\n",
    "      `C`      - The label for this new cluster.  \n",
    "      `eps`    - Threshold distance\n",
    "      `MinPts` - Minimum required number of neighbors\n",
    "    '''\n",
    "\n",
    "    # Assign the cluster label to the seed point.\n",
    "    labels[P] = C\n",
    "    \n",
    "    # Look at each neighbor of P (neighbors are referred to as Pn). \n",
    "    # NeighborPts will be used as a FIFO queue of points to search--that is, it\n",
    "    # will grow as we discover new branch points for the cluster. The FIFO\n",
    "    # behavior is accomplished by using a while-loop rather than a for-loop.\n",
    "    # In NeighborPts, the points are represented by their index in the original\n",
    "    # dataset.\n",
    "    i = 0\n",
    "    while i < len(NeighborPts):    \n",
    "        \n",
    "        # Get the next point from the queue.        \n",
    "        Pn = NeighborPts[i]\n",
    "       \n",
    "        # If Pn was labelled NOISE during the seed search, then we\n",
    "        # know it's not a branch point (it doesn't have enough neighbors), so\n",
    "        # make it a leaf point of cluster C and move on.\n",
    "        if labels[Pn] == -1:\n",
    "           labels[Pn] = C\n",
    "        \n",
    "        # Otherwise, if Pn isn't already claimed, claim it as part of C.\n",
    "        elif labels[Pn] == 0:\n",
    "            # Add Pn to cluster C (Assign cluster label C).\n",
    "            labels[Pn] = C\n",
    "            \n",
    "            # Find all the neighbors of Pn\n",
    "            PnNeighborPts = region_query(D, Pn, eps, verbose, snn, k)\n",
    "            \n",
    "            # If Pn has at least MinPts neighbors, it's a branch point!\n",
    "            # Add all of its neighbors to the FIFO queue to be searched. \n",
    "            if len(PnNeighborPts) >= MinPts:\n",
    "                NeighborPts = NeighborPts + PnNeighborPts\n",
    "            # If Pn *doesn't* have enough neighbors, then it's a leaf point.\n",
    "            # Don't queue up it's neighbors as expansion points.\n",
    "            #else:\n",
    "                # Do nothing                \n",
    "                #NeighborPts = NeighborPts               \n",
    "        \n",
    "        # Advance to the next point in the FIFO queue.\n",
    "        i += 1        \n",
    "    \n",
    "    # We've finished growing cluster C!\n",
    "\n",
    "\n",
    "def region_query(D, P, eps, verbose = True, snn = False, k = 5):\n",
    "    '''\n",
    "    Find all points in dataset `D` within distance `eps` of point `P`.\n",
    "    \n",
    "    This function calculates the distance between a point P and every other \n",
    "    point in the dataset, and then returns only those points which are within a\n",
    "    threshold distance `eps`.\n",
    "    '''\n",
    "    neighbors = []\n",
    "    \n",
    "    # For each point in the dataset...\n",
    "    for Pn in range(0, len(D)):\n",
    "        if snn:\n",
    "            if manhattan_dist(D[P], D[Pn]) < eps:\n",
    "                neighbors.append(Pn)\n",
    "        else:\n",
    "            # If the distanceis below the threshold, add it to the neighbors list.\n",
    "            if SNN(D, [D[P]], eps) < eps:\n",
    "                neighbors.append(Pn)\n",
    "    if verbose:\n",
    "        print(f\"Start point: {D[P]} reachable points: \")\n",
    "        for n in neighbors:\n",
    "            if not n == P:\n",
    "                print(f\"    - {D[n]}\")        \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point [1, 1], Cluster: -1\n",
      "Point [1, 2], Cluster: -1\n",
      "Point [2, 1], Cluster: -1\n",
      "Point [2, 2], Cluster: -1\n",
      "Point [3, 5], Cluster: -1\n",
      "Point [3, 9], Cluster: -1\n",
      "Point [3, 10], Cluster: -1\n",
      "Point [4, 10], Cluster: -1\n",
      "Point [4, 11], Cluster: -1\n",
      "Point [7, 10], Cluster: -1\n",
      "Point [9, 4], Cluster: 1\n",
      "Point [9, 5], Cluster: 1\n",
      "Point [10, 3], Cluster: 1\n",
      "Point [10, 4], Cluster: 1\n",
      "Point [10, 5], Cluster: 1\n",
      "Point [10, 6], Cluster: 1\n",
      "Point [10, 10], Cluster: -1\n",
      "Point [11, 4], Cluster: 1\n",
      "Point [11, 5], Cluster: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.cluster import DBSCAN\n",
    "points = [\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 1],\n",
    "    [2, 2],\n",
    "    [3, 5],\n",
    "    [3, 9],\n",
    "    [3, 10],\n",
    "    [4, 10],\n",
    "    [4, 11],\n",
    "    [7, 10],\n",
    "    [9, 4],\n",
    "    [9, 5],\n",
    "    [10, 3],\n",
    "    [10, 4],\n",
    "    [10, 5],\n",
    "    [10, 6],\n",
    "    [10, 10],\n",
    "    [11, 4],\n",
    "    [11, 5]\n",
    "]\n",
    "\n",
    "#dbscan(eps=3, min_samples=2, metric = \"manhattan\").fit(points)\n",
    "dbscan(points, 2, 4, False,True)\n",
    "\n",
    "#df = [x, y]\n",
    "#dbscan(eps=2, MinPts=4, D=df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa82987a71ca0339a52998cd22613b0c002bda8349fa32a0cb67ceec3936a2bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
